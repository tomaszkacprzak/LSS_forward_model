{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94651619-393c-4a05-8357-e7bb339d5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "path_data_cats = '/global/cfs/cdirs/m5099/RR2/Euclid_cats.npy'\n",
    "cats_Euclid  = np.load(path_data_cats,allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a16e51-4b72-4729-b652-6476974b15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = h5.File('/pscratch/sd/d/dhayaa/For_Marco/DECADE/ShearCatalogDR3.hdf5','r')\n",
    "for xx in ['NGC','SGC']:\n",
    "    cat = dict()\n",
    "    bin_ = np.array(catalog[xx] ['BIN'])\n",
    "    ra = np.array(catalog[xx] ['RA'])\n",
    "    dec = np.array(catalog[xx] ['DEC'])\n",
    "    e1 = np.array(catalog[xx] ['g1'])\n",
    "    e2 = np.array(catalog[xx] ['g2'])\n",
    "    w = np.array(catalog[xx] ['mcal_g_w'])\n",
    "    for i in range(1,5):\n",
    "        mask = bin_ == i \n",
    "        cat[i-1] = dict()\n",
    "        cat[i-1]['ra'] = ra[mask]\n",
    "        cat[i-1]['dec'] = dec[mask]\n",
    "        cat[i-1]['e1'] = e1[mask]- np.sum(e1*w)/np.sum(w)\n",
    "        cat[i-1]['e2'] = e2[mask]- np.sum(e2*w)/np.sum(w)\n",
    "        cat[i-1]['w'] = w[mask]\n",
    "    np.save('/global/cfs/cdirs/m5099/DESY3/DECADE_{0}.npy'.format(xx),cat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033e96d7-2e69-44a9-a485-5f6696e85e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_SGC = np.load('/pscratch/sd/d/dhayaa/For_Marco/DECADE/nofz/SGC/mean_nz_Final.npy',allow_pickle=True)\n",
    "nz_NGC = np.load('/pscratch/sd/d/dhayaa/For_Marco/DECADE/nofz/NGC/mean_nz_Final.npy',allow_pickle=True)\n",
    "\n",
    "\n",
    "min_z   = 0.01\n",
    "max_z   = 5\n",
    "delta_z = 0.05\n",
    "zbins   = np.arange(min_z,max_z+delta_z,delta_z)\n",
    "zbinsc  = zbins[:-1]+(zbins[1]-zbins[0])/2. \n",
    "\n",
    "nz_RR2= dict()\n",
    "nz_RR2['z_rebinned'] = zbinsc\n",
    "nz_RR2['nz_rebinned'] = nz_NGC\n",
    "\n",
    "np.save('/global/cfs/cdirs/m5099/DESY3/nz_NGC.npy',nz_RR2)\n",
    "\n",
    "\n",
    "nz_RR2= dict()\n",
    "nz_RR2['z_rebinned'] = zbinsc\n",
    "nz_RR2['nz_rebinned'] = nz_SGC\n",
    "\n",
    "np.save('/global/cfs/cdirs/m5099/DESY3/nz_SGC.npy',nz_RR2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190385aa-ebbf-494d-ba50-bd5e392539dc",
   "metadata": {},
   "source": [
    "# DES Y6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b9ed84b-1a15-4829-b0b5-8b66f0b8f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b14030f5-9da2-42d7-9372-41c98dc78aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import healsparse\n",
    "met = h5.File('/global/cfs/cdirs/des/y6kp-cats/final_version/metadetect_2024-11-07.hdf5','r')\n",
    "# add ra,dec  ----------------\n",
    "cat_met = dict()\n",
    "# Loop over bins to collect data\n",
    "for i in range(4):\n",
    "    cat_met[i] = dict()\n",
    "\n",
    "\n",
    "    # Collect weights\n",
    "    ra_mdet = np.array(met['noshear'][f'tomo_bin_{i}']['ra']) \n",
    "    dec_mdet = np.array(met['noshear'][f'tomo_bin_{i}']['dec']) \n",
    "\n",
    "    cat_met[i]['ra'] = ra_mdet\n",
    "    cat_met[i]['dec'] = dec_mdet\n",
    "\n",
    "    \n",
    "    ww = np.array(met['noshear'][f'tomo_bin_{i}']['w'])\n",
    "    ww_1p = np.array(met['1p'][f'tomo_bin_{i}']['w'])\n",
    "    ww_1m = np.array(met['1m'][f'tomo_bin_{i}']['w'])\n",
    "    ww_2p = np.array(met['2p'][f'tomo_bin_{i}']['w'])\n",
    "    ww_2m = np.array(met['2m'][f'tomo_bin_{i}']['w'])\n",
    "\n",
    "    # Collect g1 and g2 values\n",
    "    g1_noshear = (np.array(met['noshear'][f'tomo_bin_{i}']['gauss_g_1']))\n",
    "    g2_noshear = (np.array(met['noshear'][f'tomo_bin_{i}']['gauss_g_2']))\n",
    "\n",
    "    g1_1p = (np.array(met['1p'][f'tomo_bin_{i}']['gauss_g_1']))\n",
    "    g1_1m = (np.array(met['1m'][f'tomo_bin_{i}']['gauss_g_1']))\n",
    "    g1_2p = (np.array(met['2p'][f'tomo_bin_{i}']['gauss_g_1']))\n",
    "    g1_2m = (np.array(met['2m'][f'tomo_bin_{i}']['gauss_g_1']))\n",
    "    g2_1p = (np.array(met['1p'][f'tomo_bin_{i}']['gauss_g_2']))\n",
    "    g2_1m = (np.array(met['1m'][f'tomo_bin_{i}']['gauss_g_2']))\n",
    "    g2_2p = (np.array(met['2p'][f'tomo_bin_{i}']['gauss_g_2']))\n",
    "    g2_2m = (np.array(met['2m'][f'tomo_bin_{i}']['gauss_g_2']))\n",
    "\n",
    "\n",
    "    # Compute mean values and response matrices\n",
    "    mean_g1 = np.sum(ww * g1_noshear) / np.sum(ww)\n",
    "    mean_g1p = np.sum(ww_1p * g1_1p) / np.sum(ww_1p)\n",
    "    mean_g1m = np.sum(ww_1m * g1_1m) / np.sum(ww_1m)\n",
    "    R11 = (mean_g1p - mean_g1m) / (2 * 0.01)\n",
    "    \n",
    "    mean_g2 = np.sum(ww * g2_noshear) / np.sum(ww)\n",
    "    mean_g2p = np.sum(ww_2p * g2_2p) / np.sum(ww_2p)\n",
    "    mean_g2m = np.sum(ww_2m * g2_2m) / np.sum(ww_2m)\n",
    "    R22 = (mean_g2p - mean_g2m) / (2 * 0.01)\n",
    "\n",
    "    g1 = g1_noshear/(0.5*(R11+R22))\n",
    "    g2 = g2_noshear/(0.5*(R11+R22))\n",
    "    cat_met[i]['e1'] = g1-np.mean(g1*ww)/np.mean(ww)\n",
    "    cat_met[i]['e2'] = g2-np.mean(g2*ww)/np.mean(ww)\n",
    "    cat_met[i]['w'] = ww\n",
    "\n",
    "np.save('/global/cfs/cdirs/m5099/DESY3/DESY6.npy',cat_met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f1862df-e822-45f9-aab3-c85f8fb49369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m = np.load('/global/cfs/cdirs/m5099/DESY3/20k_m_nz_realizations.npz')\n",
    "nz_RR2= dict()\n",
    "nz_RR2['z_rebinned'] = np.arange(0,3,0.01)\n",
    "nz_RR2['nz_rebinned'] = np.mean(m['nzs'],axis=0)\n",
    "nz_RR2['nz_rebinned'][:,-1] = 0.\n",
    "np.save('/global/cfs/cdirs/m5099/DESY3/nz_DESY6.npy',nz_RR2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83133e41-bac7-45da-9d29-a7a38d9dc32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00343755,  0.0064513 ,  0.01591432,  0.00162992])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(m['ms'],axis=1)\n",
    "np.mean(m['nzs'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67d5d5dd-6a9b-452d-a2c5-704a5b3ad2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18266 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx_rel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20000\u001b[39m,\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_rel\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 18266 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "idx_rel = np.random.randint(0,20000,1)[0]\n",
    "m['ms'][idx_rel]\n",
    "m['nzs'][idx_rel][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a805526-0482-4e18-b763-04eb062eac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30127065, 0.19114114, 0.15163738, 0.11113555])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee591de-5ff8-4e2a-a403-2ff38df228b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_WL_sample(ngal_glass, zeff_glass, cosmo_bundle, sims_parameters, nside_maps, fields, cats_Euclid, SC_corrections =None,do_catalog = False, include_SC = True, compact_savings = False):\n",
    "    if include_SC:\n",
    "        corr_variance_array =  [  SC_corrections['corr_variance_fit'][tomo](sims_parameters['bias_sc'][tomo])        for tomo in range(len(ngal_glass))]\n",
    "        coeff_kurtosis_array = [  SC_corrections['coeff_kurtosis_fit'][tomo](sims_parameters['bias_sc'][tomo])       for tomo in range(len(ngal_glass))]\n",
    "        A_corr_array = [  SC_corrections['A_corr_fit'][tomo](sims_parameters['bias_sc'][tomo])                       for tomo in range(len(ngal_glass))]\n",
    "    else:\n",
    "        corr_variance_array = np.ones(len(ngal_glass))\n",
    "        coeff_kurtosis_array = np.zeros(len(ngal_glass))\n",
    "        A_corr_array  = np.ones(len(ngal_glass))\n",
    "        sims_parameters['bias_sc'] = np.zeros(len(ngal_glass))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    kappa_tot  = np.zeros((len(ngal_glass), 12*nside_maps**2))\n",
    "    g1_tot     = np.zeros((len(ngal_glass), 12*nside_maps**2))\n",
    "    g2_tot     = np.zeros((len(ngal_glass), 12*nside_maps**2))\n",
    "    d_tot      = np.zeros((len(ngal_glass), 12*nside_maps**2))\n",
    "    \n",
    "    \n",
    "    # load each lightcone output in turn and add it to the simulation\n",
    "    # note: I added a -sign to gamma to match data conventions later\n",
    "    for tomo in range(len(ngal_glass)):\n",
    "        for i in (range(len(fields['gamma']))):       \n",
    "            C1 = 5e-14\n",
    "            rho_crit0_h2 = ccl.physical_constants.RHO_CRITICAL\n",
    "            rho_c1 = C1 * rho_crit0_h2\n",
    "            IA_f = F_nla(z=zeff_glass[i],\n",
    "             om0=sims_parameters['Omega_m'],\n",
    "             A_ia=sims_parameters['A_IA'], rho_c1=rho_c1, eta=sims_parameters['eta_IA'], z0=0.67,\n",
    "             cosmo=cosmo_bundle['cosmo_pyccl'])\n",
    "            \n",
    "            g1_tot[tomo] += ngal_glass[tomo,i] * (-fields['gamma'][i][0].real-fields['IA_shear'][i][0].real*IA_f) * (1 + sims_parameters['bias_sc'][tomo] * fields['density'][i])\n",
    "            g2_tot[tomo] += ngal_glass[tomo,i] * (-fields['gamma'][i][0].imag-fields['IA_shear'][i][0].imag*IA_f) * (1 + sims_parameters['bias_sc'][tomo] * fields['density'][i])\n",
    "            d_tot[tomo]  += ngal_glass[tomo,i] * (1 + sims_parameters['bias_sc'][tomo] * fields['density'][i] )\n",
    "       \n",
    "    \n",
    "    sims_parameters.setdefault('rot', 0)\n",
    "    sims_parameters.setdefault('delta_rot', 0)\n",
    "\n",
    "    maps_sim = dict()\n",
    "    for tomo in range(len(ngal_glass)):\n",
    "        maps_sim[tomo] = dict()\n",
    "\n",
    "\n",
    "\n",
    "        pix_ = convert_to_pix_coord(cats_Euclid[tomo]['ra'],cats_Euclid[tomo]['dec'], nside=nside_maps*2)\n",
    "        pix = rotate_and_rebin(pix_, nside_maps, sims_parameters['rot'], delta_=sims_parameters['delta_rot'])\n",
    "             \n",
    "\n",
    "        # source clustering term ~\n",
    "        f = 1./np.sqrt(d_tot[tomo])\n",
    "        f = f[pix]\n",
    "    \n",
    "    \n",
    "        n_map = np.zeros(hp.nside2npix(nside_maps))\n",
    "        n_map_sc = np.zeros(hp.nside2npix(nside_maps))\n",
    "    \n",
    "                        \n",
    "        unique_pix, idx, idx_rep = np.unique(pix, return_index=True, return_inverse=True)\n",
    "    \n",
    "    \n",
    "        n_map_sc[unique_pix] += np.bincount(idx_rep, weights=cats_Euclid[tomo]['w']/f**2)\n",
    "        n_map[unique_pix] += np.bincount(idx_rep, weights=cats_Euclid[tomo]['w'])\n",
    "    \n",
    "        g1_ = g1_tot[tomo][pix]\n",
    "        g2_ = g2_tot[tomo][pix]\n",
    "    \n",
    "    \n",
    "        es1,es2 = apply_random_rotation(cats_Euclid[tomo]['e1']/f, cats_Euclid[tomo]['e2']/f)\n",
    "        es1_ref,es2_ref = apply_random_rotation(cats_Euclid[tomo]['e1'], cats_Euclid[tomo]['e2'])\n",
    "        es1a,es2a = apply_random_rotation(cats_Euclid[tomo]['e1']/f, cats_Euclid[tomo]['e2']/f)\n",
    "    \n",
    "    \n",
    "        #x1_sc,x2_sc = addSourceEllipticity({'shear1':g1_,'shear2':g2_},{'e1':es1,'e2':es2},es_colnames=(\"e1\",\"e2\"))\n",
    "    \n",
    "    \n",
    "        e1r_map = np.zeros(hp.nside2npix (nside_maps))\n",
    "        e2r_map = np.zeros(hp.nside2npix (nside_maps))\n",
    "        e1r_map0 = np.zeros(hp.nside2npix(nside_maps))\n",
    "        e2r_map0 = np.zeros(hp.nside2npix(nside_maps))\n",
    "        e1r_map0_ref = np.zeros(hp.nside2npix(nside_maps))\n",
    "        e2r_map0_ref = np.zeros(hp.nside2npix(nside_maps))\n",
    "        g1_map = np.zeros(hp.nside2npix(nside_maps))\n",
    "        g2_map = np.zeros(hp.nside2npix(nside_maps))\n",
    "    \n",
    "        unique_pix, idx, idx_rep = np.unique(pix, return_index=True, return_inverse=True)\n",
    "    \n",
    "    \n",
    "        e1r_map[unique_pix] += np.bincount(idx_rep, weights=es1*cats_Euclid[tomo]['w'])\n",
    "        e2r_map[unique_pix] += np.bincount(idx_rep, weights=es2*cats_Euclid[tomo]['w'])\n",
    "    \n",
    "        e1r_map0[unique_pix] += np.bincount(idx_rep, weights=es1a*cats_Euclid[tomo]['w'])\n",
    "        e2r_map0[unique_pix] += np.bincount(idx_rep, weights=es2a*cats_Euclid[tomo]['w'])\n",
    "    \n",
    "        e1r_map0_ref[unique_pix] += np.bincount(idx_rep, weights=es1_ref*cats_Euclid[tomo]['w'])\n",
    "        e2r_map0_ref[unique_pix] += np.bincount(idx_rep, weights=es2_ref*cats_Euclid[tomo]['w'])\n",
    "    \n",
    "    \n",
    "        mask_sims = n_map_sc != 0.\n",
    "        e1r_map[mask_sims]  = e1r_map[mask_sims]/(n_map_sc[mask_sims])\n",
    "        e2r_map[mask_sims] =  e2r_map[mask_sims]/(n_map_sc[mask_sims])\n",
    "        e1r_map0[mask_sims]  = e1r_map0[mask_sims]/(n_map_sc[mask_sims])\n",
    "        e2r_map0[mask_sims] =  e2r_map0[mask_sims]/(n_map_sc[mask_sims])\n",
    "        e1r_map0_ref[mask_sims]  = e1r_map0_ref[mask_sims]/(n_map[mask_sims])\n",
    "        e2r_map0_ref[mask_sims] =  e2r_map0_ref[mask_sims]/(n_map[mask_sims])\n",
    "    \n",
    "    \n",
    "    \n",
    "        var_ =  e1r_map0_ref**2+e2r_map0_ref**2\n",
    "    \n",
    "    \n",
    "        #'''\n",
    "        e1r_map   *= 1/(np.sqrt(A_corr_array[tomo]*corr_variance_array[tomo])) * np.sqrt((1+coeff_kurtosis_array[tomo]*var_))\n",
    "        e2r_map   *= 1/(np.sqrt(A_corr_array[tomo]*corr_variance_array[tomo])) * np.sqrt((1+coeff_kurtosis_array[tomo]*var_))\n",
    "        e1r_map0  *= 1/(np.sqrt(A_corr_array[tomo]*corr_variance_array[tomo])) * np.sqrt((1+coeff_kurtosis_array[tomo]*var_))\n",
    "        e2r_map0  *= 1/(np.sqrt(A_corr_array[tomo]*corr_variance_array[tomo])) * np.sqrt((1+coeff_kurtosis_array[tomo]*var_))\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        #'''\n",
    "        g1_map[unique_pix] += np.bincount(idx_rep, weights= g1_*cats_Euclid[tomo]['w'])\n",
    "        g2_map[unique_pix] += np.bincount(idx_rep, weights= g2_*cats_Euclid[tomo]['w'])\n",
    "    \n",
    "    \n",
    "    \n",
    "        g1_map[mask_sims]  = g1_map[mask_sims]/(n_map_sc[mask_sims])\n",
    "        g2_map[mask_sims] =  g2_map[mask_sims]/(n_map_sc[mask_sims])\n",
    "\n",
    "        if compact_savings:\n",
    "            e1_ = ((g1_map+e1r_map0))[mask_sims]\n",
    "            e2_ = ((g2_map+e2r_map0))[mask_sims]\n",
    "            g1_ = g1_map[mask_sims]\n",
    "            g2_ = g2_map[mask_sims]\n",
    "            e1n_ = ( e1r_map)[mask_sims]\n",
    "            e2n_ = ( e2r_map)[mask_sims]\n",
    "            idx_ = np.arange(len(mask_sims))[mask_sims]\n",
    "        \n",
    "            maps_sim[tomo] =     {'g1_map':g1_,'g2_map':g2_,'e1':e1_,'e2':e2_,'e1n':e1n_,'e2n':e2n_,\n",
    "                                    'idx_':idx_}\n",
    "\n",
    "            \n",
    "        else:\n",
    "            e1_ = ((g1_map+e1r_map0))#[mask_sims]\n",
    "            e2_ = ((g2_map+e2r_map0))#[mask_sims]\n",
    "            e1n_ = ( e1r_map)#[mask_sims]\n",
    "            e2n_ = ( e2r_map)#[mask_sims]\n",
    "           # idx_ = np.arange(len(mask_sims))[mask_sims]\n",
    "        \n",
    "            maps_sim[tomo] =     {'g1_map':g1_map,'g2_map':g2_map,'e1':e1_,'e2':e2_,'e1n':e1n_,'e2n':e2n_,\n",
    "                                    'e1r_map0_ref':e1r_map0_ref,\n",
    "                                    'e2r_map0_ref':e2r_map0_ref,\n",
    "                                    'var_':var_}     \n",
    "    \n",
    "        if do_catalog:\n",
    "    \n",
    "            cats_sim = dict()\n",
    "            # make a catalog ---------------------------------------------------------------------------------------------------------------------------------\n",
    "            SC_per_pixel_correction_noise  = f**2/((np.sqrt(A_corr_array[tomo]*corr_variance_array[tomo])) * np.sqrt((1+coeff_kurtosis_array[tomo]*var_)))[pix]\n",
    "            \n",
    "            # the f**2 applied to g1,g2 is the normalisation missing in the g1_tot,g2_tot ---------------------------------------------------\n",
    "            e1_SC = g1_*f**2+es1a*SC_per_pixel_correction_noise\n",
    "            e2_SC = g2_*f**2+es2a*SC_per_pixel_correction_noise\n",
    "            #e1_SC,e2_SC = addSourceEllipticity({'shear1':g1_,'shear2':g2_},{'e1':es1a*SC_per_pixel_correction_noise,'e2':es2a*SC_per_pixel_correction_noise},es_colnames=(\"e1\",\"e2\"))\n",
    "            cats_sim[tomo] =  {'ra':cats_Euclid[tomo]['ra'],'dec':cats_Euclid[tomo]['dec'],'e1':e1_SC,'e2':e2_SC,'w':cats_Euclid[tomo]['w']}\n",
    "        \n",
    "        else:\n",
    "            cats_sim = None\n",
    "            \n",
    "    return maps_sim, cats_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyccl_env",
   "language": "python",
   "name": "pyccl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
